{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "# Import custom methods to work with Apache Cassandra\n",
    "from lib import generate_str, create_table, insert_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            # The rows without artist information (empty strings) are skipped\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This cell creates a keyspace\n",
    "\n",
    "try:\n",
    "    query = \"CREATE  KEYSPACE IF NOT EXISTS sparkify \\\n",
    "             WITH REPLICATION = {'class' : 'SimpleStrategy',\\\n",
    "                                 'replication_factor' : 1}\"\n",
    "    session.execute(query)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This cell sets the keyspace to the one created above\n",
    "\n",
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run. As a best practice it is recomended to run assign one table per query since JOIN and GROUP BY statements are not supported in Apache Cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession = 4\n",
    "\n",
    "CQL Query:\n",
    "```\n",
    "SELECT artist, song, length FROM <table_name> WHERE sessionId = 228 AND itemInSession = 4\n",
    "```\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "CQL Query: song must be sorted by itemInSession\n",
    "```\n",
    "SELECT artist, song, firstName, lastName FROM <table_name> WHERE userid = 10 AND sessionid = 182\n",
    "```\n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "CQL Query:\n",
    "```\n",
    "SELECT firstName, lastName FROM <table_name> WHERE song 'All Hands Against His Own'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table table_events was dropped\n",
      "Table table_events was created\n",
      "Inserting ./event_datafile_new.csv data into table table_events\n"
     ]
    }
   ],
   "source": [
    "# We are going to load all the data in './event_datafile_new.csv' into a single table with sessionId as PRIMARY KEY. \n",
    "# This is thought as a helper table just in case we want to take a look into certain fields.\n",
    "\n",
    "# \"table_events\" creation\n",
    "table = \"table_events\"\n",
    "fields_events = \"(artist text, \\\n",
    "            firstName text, \\\n",
    "            gender text, \\\n",
    "            itemInSession int, \\\n",
    "            lastName text, \\\n",
    "            length double, \\\n",
    "            level text, \\\n",
    "            location text, \\\n",
    "            sessionId int, \\\n",
    "            song text, \\\n",
    "            userId int, \\\n",
    "            PRIMARY KEY (sessionId))\"\n",
    "create_table(table_name = table, fields = fields_events, session = session)\n",
    "\n",
    "# data insertion into \"table_events\"\n",
    "file = 'event_datafile_new.csv'\n",
    "fields = ['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "          'level','location','sessionId','song','userId']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    print(\"Inserting ./\"+file+\" data into table \"+table)\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[0], line[1], line[2], int(line[3]), line[4], float(line[5]),\\\n",
    "          line[6], line[7], int(line[8]), line[9], int(line[10])]\n",
    "\n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT COUNT(*) FROM table_events\n",
      "Output:\n",
      "Row(count=41)\n",
      "\n",
      "Query: SELECT * FROM table_events LIMIT 5\n",
      "Output:\n",
      "(363, 'Alphaville', 'Lily', 'F', 0, 'Burns', 285.43955, 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'Big In Japan (Original)', 32)\n",
      "(331, 'Amy Winehouse', 'Martin', 'M', 2, 'Johnson', 141.24363, 'free', 'Minneapolis-St. Paul-Bloomington, MN-WI', 'Some Unholy War', 55)\n",
      "(340, 'Barry Tuckwell/Academy of St Martin-in-the-Fields/Sir Neville Marriner', 'Theodore', 'M', 0, 'Harris', 277.15873, 'free', 'Red Bluff, CA', 'Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)', 14)\n",
      "(423, 'Tub Ring', 'Cecilia', 'F', 0, 'Owens', 233.69098, 'free', 'Atlanta-Sandy Springs-Roswell, GA', 'Invalid', 6)\n",
      "(420, 'Aerosmith', 'Lily', 'F', 0, 'Burns', 301.76608, 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'Fly Away From Here', 32)\n"
     ]
    }
   ],
   "source": [
    "# To verify that all the rows were inserted we will run two queries:\n",
    "\n",
    "# 1 - row count: \"SELECT COUNT(*) FROM table1\"\n",
    "print(\"Query: \" + \"SELECT COUNT(*) FROM {}\".format(table))\n",
    "print(\"Output:\")\n",
    "rows = session.execute(\"SELECT COUNT(*) FROM {}\".format(table))\n",
    "for r in rows:\n",
    "    print(r)\n",
    "\n",
    "print(\"\\nQuery: \" + \"SELECT * FROM {} LIMIT 5\".format(table))\n",
    "print(\"Output:\")\n",
    "# 2 - check all the data: \"SELECT * FROM table1\"\n",
    "rows = session.execute(\"SELECT * FROM {} LIMIT 5\".format(table))\n",
    "for r in rows:\n",
    "    print(r[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table table1 was dropped\n",
      "Table table1 was created\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "table = \"table1\"\n",
    "fields1_create = \"(artist text, \\\n",
    "            itemInSession int, \\\n",
    "            length double, \\\n",
    "            sessionId int, \\\n",
    "            song text, \\\n",
    "            PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "create_table(table_name = table, fields = fields1_create, session = session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "fields1 = ['artist','itemInSession','length','sessionId','song']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields1, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[0], int(line[3]), float(line[5]), int(line[8]), line[9]]\n",
    "        \n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(sessionid=297, iteminsession=4, artist='Evanescence', length=237.11302, song='Bring Me To Life')\n",
      "Row(count=263)\n"
     ]
    }
   ],
   "source": [
    "# We now run the query1 to verify that the table is modeled according to the desired output\n",
    "# The original request for this project was sessionId = 228 but there is no such entry so instead I used sessionid=297\n",
    "query1 = \"SELECT * FROM {} WHERE sessionId = 297 and itemInSession = 4\".format(table)\n",
    "\n",
    "rows = session.execute(query1)\n",
    "for r in rows:\n",
    "    print(r)\n",
    "\n",
    "query_count_check = \"SELECT COUNT(*) FROM {}\".format(table)\n",
    "\n",
    "rows = session.execute(query_count_check)\n",
    "for r in rows:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### COPY AND REPEAT THE ABOVE THREE CELLS FOR EACH OF THE THREE QUESTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table table2 was dropped\n",
      "Table table2 was created\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "table = \"table2\"\n",
    "fields2_create = \"(artist text, \\\n",
    "            song text, \\\n",
    "            firstName text, \\\n",
    "            lastName text, \\\n",
    "            itemInSession int, \\\n",
    "            userId int, \\\n",
    "            sessionId int, \\\n",
    "            PRIMARY KEY ((userid, sessionid), itemInSession))\"\n",
    "\n",
    "create_table(table_name = table, fields = fields2_create, session = session)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "fields2 = ['artist', 'song', 'firstName','lastName','itemInSession','userId','sessionId']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields2, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[0], line[9], line[1], line[4], int(line[3]), int(line[10]), int(line[8])]\n",
    "        \n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 275 1 Supermassive Black Hole (Twilight Soundtrack Version)\n",
      "42 275 2 Lighten Up\n",
      "42 275 3 Pienso En Ti\n",
      "42 275 4 Amor Prohibido\n",
      "42 275 5 Day 'N' Nite\n",
      "42 275 6 Black Masks & Gasoline\n",
      "42 275 7 I'm Like A Lawyer With The Way I'm Always Trying To Get You Off (Me & You)\n",
      "42 275 8 Staple It Together\n",
      "42 275 9 Slow Jamz (Feat. Kanye West & Jamie Foxx) (Edited Album Version)\n",
      "42 275 10 Hey_ Soul Sister\n",
      "42 275 11 Rehab\n",
      "42 275 12 Van Helsing Boombox\n",
      "42 275 13 The Stallion\n",
      "42 275 14 Fireflies\n",
      "42 275 15 I Want I Want\n",
      "42 275 16 Railway\n",
      "42 275 17 Clark Gable (Album)\n",
      "42 275 18 Phaeton\n",
      "42 275 19 Ucci Ucci feat. Nicki Minaj & The Chopper City Boyz\n",
      "42 275 20 Choke\n",
      "42 275 21 Stuck Between\n",
      "42 275 22 Smell Of Desire.\n",
      "42 275 23 Headlights Look Like Diamonds\n",
      "42 275 25 Out Go The Lights\n",
      "42 275 26 You & Me Song\n",
      "42 275 27 Girls (Album version)\n",
      "42 275 28 Wayfaring Stranger\n",
      "42 275 29 Sweep The Flo (Featuring Diamond)\n",
      "42 275 30 This Old House w/ When The Saints Medley\n",
      "42 275 31 Brain Leech\n",
      "42 275 32 Didgeridoo\n",
      "42 275 33 LÃÂ  OÃÂ¹ Je Pars\n",
      "42 275 34 I Wouldn't Be A Man\n",
      "Row(count=263)\n"
     ]
    }
   ],
   "source": [
    "# We now run the query2 to verify that the table is modeled according to the desired output\n",
    "# The original request for this project was userid = 10 and sessionid 182 but there is no such entry\n",
    "# so I adjusted the values of userid and sessionid\n",
    "\n",
    "query2 = \"SELECT * FROM {} WHERE userid = 42 AND sessionid = 275\".format(table)\n",
    "\n",
    "rows = session.execute(query2)\n",
    "for r in rows:\n",
    "    print(r.userid, r.sessionid, r.iteminsession, r.song)\n",
    "\n",
    "query_count_check = \"SELECT COUNT(*) FROM {}\".format(table)\n",
    "\n",
    "rows = session.execute(query_count_check)\n",
    "for r in rows:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table table3 was dropped\n",
      "Table table3 was created\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "table = \"table3\"\n",
    "fields2_create = \"(firstName text, \\\n",
    "            lastName text, \\\n",
    "            sessionId int, \\\n",
    "            song text, \\\n",
    "            PRIMARY KEY (song, sessionid))\"\n",
    "\n",
    "create_table(table_name = table, fields = fields2_create, session = session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We have provided part of the code to set up the CSV file. Please complete the Apache Cassandra code below#\n",
    "file = 'event_datafile_new.csv'\n",
    "fields3 = ['firstName','lastName','sessionId','song']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields3, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[1], line[4], int(line[8]), line[9]]        \n",
    "        \n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I Second That Emotion', 297, 'Jayden', 'Graves')\n",
      "Row(count=263)\n"
     ]
    }
   ],
   "source": [
    "# We now run the query3 to verify that the table is modeled according to the desired output\n",
    "\n",
    "query3 = \"SELECT * FROM {} WHERE song = 'I Second That Emotion'\".format(table)\n",
    "\n",
    "rows = session.execute(query3)\n",
    "for r in rows:\n",
    "    print(r[:])\n",
    "\n",
    "query_count_check = \"SELECT COUNT(*) FROM {}\".format(table)\n",
    "\n",
    "rows = session.execute(query_count_check)\n",
    "for r in rows:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## TO-DO: Drop the table before closing out the sessions\n",
    "for table in [\"table_events\", \"table1\", \"table2\", \"table3\"]:\n",
    "            session.execute(\"DROP TABLE IF EXISTS {}\".format(table_name))\n",
    "        print(\"Table {} was dropped\".format(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
