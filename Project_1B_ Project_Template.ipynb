{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "# Import custom methods to work with Apache Cassandra\n",
    "from lib import generate_str, create_table, insert_query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    # join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "    # reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    "        # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "#print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            # The rows without artist information (empty strings) are skipped\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Complete the Apache Cassandra coding portion of your project. \n",
    "\n",
    "## Now you are ready to work with the CSV file titled <font color=red>event_datafile_new.csv</font>, located within the Workspace directory.  The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Begin writing your Apache Cassandra code in the cells below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    query = \"CREATE  KEYSPACE IF NOT EXISTS sparkify \\\n",
    "             WITH REPLICATION = {'class' : 'SimpleStrategy',\\\n",
    "                                 'replication_factor' : 1}\"\n",
    "    session.execute(query)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace('sparkify')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Now we need to create tables to run the following queries. Remember, with Apache Cassandra you model the database tables on the queries you want to run. As a best practice it is recomended to run assign one table per query since JOIN and GROUP BY statements are not supported in Apache Cassandra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Create queries to ask the following three questions of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession = 4\n",
    "\n",
    "CQL Query:\n",
    "```\n",
    "SELECT artist, song, length FROM <table_name> WHERE sessionId = 228 AND itemInSession = 4\n",
    "```\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "CQL Query: song must be sorted by itemInSession\n",
    "```\n",
    "SELECT artist, song, firstName, lastName FROM <table_name> WHERE userid = 10 AND sessionid = 182\n",
    "```\n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "CQL Query:\n",
    "```\n",
    "SELECT firstName, lastName FROM <table_name> WHERE song = 'All Hands Against His Own'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table table_events was dropped\n",
      "Table table_events was created\n",
      "Inserting ./event_datafile_new.csv data into table table_events\n"
     ]
    }
   ],
   "source": [
    "# For further insight we are going to load all the data in './event_datafile_new.csv' \n",
    "# into a single table with sessionId as PRIMARY KEY. \n",
    "# This is thought as a helper table just in case we want to take a look into certain fields.\n",
    "\n",
    "# \"table_events\" creation\n",
    "table = \"table_events\"\n",
    "fields_events = \"(artist text, \\\n",
    "            firstName text, \\\n",
    "            gender text, \\\n",
    "            itemInSession int, \\\n",
    "            lastName text, \\\n",
    "            length double, \\\n",
    "            level text, \\\n",
    "            location text, \\\n",
    "            sessionId int, \\\n",
    "            song text, \\\n",
    "            userId int, \\\n",
    "            PRIMARY KEY (sessionId))\"\n",
    "create_table(table_name = table, fields = fields_events, session = session)\n",
    "\n",
    "# data insertion into \"table_events\"\n",
    "file = 'event_datafile_new.csv'\n",
    "fields = ['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "          'level','location','sessionId','song','userId']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    print(\"Inserting ./\"+file+\" data into table \"+table)\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[0], line[1], line[2], int(line[3]), line[4], float(line[5]),\\\n",
    "          line[6], line[7], int(line[8]), line[9], int(line[10])]\n",
    "\n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: SELECT COUNT(*) FROM table_events\n",
      "Output:\n",
      "Row(count=41)\n",
      "\n",
      "Query: SELECT * FROM table_events LIMIT 5\n",
      "Output:\n",
      "(363, 'Alphaville', 'Lily', 'F', 0, 'Burns', 285.43955, 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'Big In Japan (Original)', 32)\n",
      "(331, 'Amy Winehouse', 'Martin', 'M', 2, 'Johnson', 141.24363, 'free', 'Minneapolis-St. Paul-Bloomington, MN-WI', 'Some Unholy War', 55)\n",
      "(340, 'Barry Tuckwell/Academy of St Martin-in-the-Fields/Sir Neville Marriner', 'Theodore', 'M', 0, 'Harris', 277.15873, 'free', 'Red Bluff, CA', 'Horn Concerto No. 4 in E flat K495: II. Romance (Andante cantabile)', 14)\n",
      "(423, 'Tub Ring', 'Cecilia', 'F', 0, 'Owens', 233.69098, 'free', 'Atlanta-Sandy Springs-Roswell, GA', 'Invalid', 6)\n",
      "(420, 'Aerosmith', 'Lily', 'F', 0, 'Burns', 301.76608, 'free', 'New York-Newark-Jersey City, NY-NJ-PA', 'Fly Away From Here', 32)\n"
     ]
    }
   ],
   "source": [
    "# To verify that all the rows were inserted we will run two queries:\n",
    "\n",
    "# 1 - row count: \"SELECT COUNT(*) FROM table1\"\n",
    "print(\"Query: \" + \"SELECT COUNT(*) FROM {}\".format(table))\n",
    "print(\"Output:\")\n",
    "rows = session.execute(\"SELECT COUNT(*) FROM {}\".format(table))\n",
    "for r in rows:\n",
    "    print(r)\n",
    "\n",
    "print(\"\\nQuery: \" + \"SELECT * FROM {} LIMIT 5\".format(table))\n",
    "print(\"Output:\")\n",
    "# 2 - check all the data: \"SELECT * FROM table1\"\n",
    "rows = session.execute(\"SELECT * FROM {} LIMIT 5\".format(table))\n",
    "for r in rows:\n",
    "    print(r[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 1: Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession = 4\n",
    "\n",
    "CQL Query:\n",
    "```\n",
    "SELECT artist, song, length FROM <table_name> WHERE sessionId = 338 AND itemInSession = 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table artist_song was dropped\n",
      "Table artist_song was created\n"
     ]
    }
   ],
   "source": [
    "# Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "# sessionId = 338, and itemInSession = 4\n",
    "\n",
    "table = \"artist_song\"\n",
    "fields1_create = \"(artist text, \\\n",
    "            itemInSession int, \\\n",
    "            length double, \\\n",
    "            sessionId int, \\\n",
    "            song text, \\\n",
    "            PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "create_table(table_name = table, fields = fields1_create, session = session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "fields1 = ['artist','itemInSession','length','sessionId','song']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields1, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[0], int(line[3]), float(line[5]), int(line[8]), line[9]]\n",
    "        \n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Selena', 'Amor Prohibido', 172.66893)\n"
     ]
    }
   ],
   "source": [
    "# We now run the query1 to verify that the table is modeled according to the desired output\n",
    "# The original request for this query was sessionId = 338 \n",
    "# unfortunately there is no such entry in the file ./'event_datafile_new.csv' so I will use another sessionID\n",
    "\n",
    "query1 = \"SELECT artist, song, length FROM {} WHERE sessionId = 275 AND itemInSession = 4\".format(table)\n",
    "\n",
    "rows = session.execute(query1)\n",
    "for r in rows:\n",
    "    #print(r.artist, r.song, r.length)\n",
    "    print(r[:])\n",
    "    \n",
    "# Uncomment this part to check the total number of rows in table1    \n",
    "#query_count_check = \"SELECT COUNT(*) FROM {}\".format(table)\n",
    "\n",
    "#rows = session.execute(query_count_check)\n",
    "#for r in rows:\n",
    "#    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "CQL Query: song must be sorted by itemInSession\n",
    "```\n",
    "SELECT artist, song, firstName, lastName FROM <table_name> WHERE userid = 10 AND sessionid = 182\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table user_playlist_songs was dropped\n",
      "Table user_playlist_songs was created\n"
     ]
    }
   ],
   "source": [
    "# Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "# for userid = 10, sessionid = 182\n",
    "\n",
    "table = \"user_playlist_songs\"\n",
    "fields2_create = \"(artist text, \\\n",
    "            song text, \\\n",
    "            firstName text, \\\n",
    "            lastName text, \\\n",
    "            itemInSession int, \\\n",
    "            userId int, \\\n",
    "            sessionId int, \\\n",
    "            PRIMARY KEY ((userid, sessionid), itemInSession))\"\n",
    "\n",
    "create_table(table_name = table, fields = fields2_create, session = session)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "fields2 = ['artist', 'song', 'firstName','lastName','itemInSession','userId','sessionId']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields2, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[0], line[9], line[1], line[4], int(line[3]), int(line[10]), int(line[8])]\n",
    "        \n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Muse', 'Supermassive Black Hole (Twilight Soundtrack Version)', 'Harper', 'Barrett')\n",
      "(2, 'Beastie Boys', 'Lighten Up', 'Harper', 'Barrett')\n",
      "(3, 'Shakira', 'Pienso En Ti', 'Harper', 'Barrett')\n",
      "(4, 'Selena', 'Amor Prohibido', 'Harper', 'Barrett')\n",
      "(5, 'Kid Cudi Vs Crookers', \"Day 'N' Nite\", 'Harper', 'Barrett')\n",
      "(6, 'Rise Against', 'Black Masks & Gasoline', 'Harper', 'Barrett')\n",
      "(7, 'Fall Out Boy', \"I'm Like A Lawyer With The Way I'm Always Trying To Get You Off (Me & You)\", 'Harper', 'Barrett')\n",
      "(8, 'Jack Johnson', 'Staple It Together', 'Harper', 'Barrett')\n",
      "(9, 'Twista feat. Kayne West & Jamie Foxx', 'Slow Jamz (Feat. Kanye West & Jamie Foxx) (Edited Album Version)', 'Harper', 'Barrett')\n",
      "(10, 'Train', 'Hey_ Soul Sister', 'Harper', 'Barrett')\n",
      "(11, 'Rihanna', 'Rehab', 'Harper', 'Barrett')\n",
      "(12, 'Man Man', 'Van Helsing Boombox', 'Harper', 'Barrett')\n",
      "(13, 'Ween', 'The Stallion', 'Harper', 'Barrett')\n",
      "(14, 'Charttraxx Karaoke', 'Fireflies', 'Harper', 'Barrett')\n",
      "(15, 'Digitalism', 'I Want I Want', 'Harper', 'Barrett')\n",
      "(16, 'Dispatch', 'Railway', 'Harper', 'Barrett')\n",
      "(17, 'Postal Service', 'Clark Gable (Album)', 'Harper', 'Barrett')\n",
      "(18, 'Patricia Barber', 'Phaeton', 'Harper', 'Barrett')\n",
      "(19, 'Enur', 'Ucci Ucci feat. Nicki Minaj & The Chopper City Boyz', 'Harper', 'Barrett')\n",
      "(20, 'Hybrid', 'Choke', 'Harper', 'Barrett')\n",
      "(21, 'Riverside', 'Stuck Between', 'Harper', 'Barrett')\n",
      "(22, 'Enigma', 'Smell Of Desire.', 'Harper', 'Barrett')\n",
      "(23, 'Arcade Fire', 'Headlights Look Like Diamonds', 'Harper', 'Barrett')\n",
      "(25, 'Spoon', 'Out Go The Lights', 'Harper', 'Barrett')\n",
      "(26, 'The Wannadies', 'You & Me Song', 'Harper', 'Barrett')\n",
      "(27, 'Tricky', 'Girls (Album version)', 'Harper', 'Barrett')\n",
      "(28, 'Tony Rice', 'Wayfaring Stranger', 'Harper', 'Barrett')\n",
      "(29, 'Rasheeda', 'Sweep The Flo (Featuring Diamond)', 'Harper', 'Barrett')\n",
      "(30, 'George Younce', 'This Old House w/ When The Saints Medley', 'Harper', 'Barrett')\n",
      "(31, 'Alex Gopher', 'Brain Leech', 'Harper', 'Barrett')\n",
      "(32, 'Aphex Twin', 'Didgeridoo', 'Harper', 'Barrett')\n",
      "(33, 'Emmanuel Moire', 'LÃ\\x83Â\\xa0 OÃ\\x83Â¹ Je Pars', 'Harper', 'Barrett')\n",
      "(34, 'Josh Turner', \"I Wouldn't Be A Man\", 'Harper', 'Barrett')\n"
     ]
    }
   ],
   "source": [
    "# We now run the query2 to verify that the table is modeled according to the desired output\n",
    "# The original request for this query was userid = 10 and sessionid = 182 \n",
    "# unfortunately there is no such entry in the file ./'event_datafile_new.csv' so I will use another sessionID\n",
    "\n",
    "query2 = \"SELECT iteminsession, artist, song, firstName, lastName FROM {} WHERE userid = 42 AND sessionid = 275\".format(table)\n",
    "\n",
    "rows = session.execute(query2)\n",
    "for r in rows:\n",
    "    #print(r.iteminsession, r.artist, r.song, r.firstname, r.lastname)\n",
    "    print(r[:])\n",
    "\n",
    "# Uncomment this part to check the total number of rows in table2    \n",
    "#query_count_check = \"SELECT COUNT(*) FROM {}\".format(table)\n",
    "\n",
    "#rows = session.execute(query_count_check)\n",
    "#for r in rows:\n",
    "#    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "CQL Query:\n",
    "```\n",
    "SELECT firstName, lastName FROM <table_name> WHERE song = 'All Hands Against His Own'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table user_song was dropped\n",
      "Table user_song was created\n"
     ]
    }
   ],
   "source": [
    "# Query 3: Give me every user name (first and last) \n",
    "# in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "table = \"user_song\"\n",
    "fields2_create = \"(firstName text, \\\n",
    "            lastName text, \\\n",
    "            sessionId int, \\\n",
    "            song text, \\\n",
    "            PRIMARY KEY (song, sessionid))\"\n",
    "\n",
    "create_table(table_name = table, fields = fields2_create, session = session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "fields3 = ['firstName','lastName','sessionId','song']\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # to skip header\n",
    "    \n",
    "    for line in csvreader:\n",
    "        query = insert_query(fields3, table)\n",
    "        # Since we are reading from CSV files we need to transform the type of the fields to\n",
    "        # match the schema of the table. There is the option to implement this automatically\n",
    "        # with the QUOTE_NONNUMERIC option [1] but this way we have more control over the data\n",
    "        #\n",
    "        # [1] https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "        values = [line[1], line[4], int(line[8]), line[9]]        \n",
    "        \n",
    "        session.execute(query, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jayden Graves\n"
     ]
    }
   ],
   "source": [
    "# We now run the query3 to verify that the table is modeled according to the desired output\n",
    "# The original request for this query was song = 'All Hands Against His Own'  \n",
    "# unfortunately there is no such entry in the file ./'event_datafile_new.csv' so I will use another song\n",
    "\n",
    "query3 = \"SELECT firstName, lastName FROM {} WHERE song = 'I Second That Emotion'\".format(table)\n",
    "\n",
    "rows = session.execute(query3)\n",
    "for r in rows:\n",
    "    print(r.firstname, r.lastname)\n",
    "\n",
    "# Uncomment this part to check the total number of rows in table3    \n",
    "#query_count_check = \"SELECT COUNT(*) FROM {}\".format(table)\n",
    "\n",
    "#rows = session.execute(query_count_check)\n",
    "#for r in rows:\n",
    "#    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table table_events was dropped\n",
      "Table artist_song was dropped\n",
      "Table user_playlist_songs was dropped\n",
      "Table user_songs was dropped\n"
     ]
    }
   ],
   "source": [
    "# Clean up: the tables are dropped before closing out the session\n",
    "for table in [\"table_events\", \"artist_song\", \"user_playlist_songs\", \"user_songs\"]:\n",
    "    session.execute(\"DROP TABLE IF EXISTS {}\".format(table))\n",
    "    print(\"Table {} was dropped\".format(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
